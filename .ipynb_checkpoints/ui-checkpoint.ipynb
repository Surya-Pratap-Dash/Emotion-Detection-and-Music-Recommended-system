{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4605965-20aa-49fa-b823-7b1a76212a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-15 23:03:54.519 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-15 23:03:54.525 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-10-15 23:03:54.530 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-15 23:03:58.447 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\SURYA PRATAP DASH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-10-15 23:03:58.450 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-15 23:03:58.454 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-15 23:03:58.456 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-15 23:03:58.459 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-15 23:03:58.461 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-15 23:03:58.462 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-15 23:03:58.466 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-15 23:03:58.467 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import io\n",
    "from PIL import Image\n",
    "import traceback\n",
    "\n",
    "print(\"--- Initializing MoodMate ---\")\n",
    "\n",
    "# --- Step 2: Define the MusicRecommender Class ---\n",
    "class MusicRecommender:\n",
    "    def __init__(self, data_path):\n",
    "        self.emotion_to_music_map = {\n",
    "            'happy': 'upbeat happy energetic dance pop joy', 'sad': 'sad mellow slow acoustic blues classical instrumental',\n",
    "            'angry': 'angry rock metal intense heavy punk industrial', 'fear': 'ambient experimental instrumental calm classical soothing',\n",
    "            'surprise': 'electronic pop dance energetic new wave synthpop', 'neutral': 'lounge chill instrumental ambient pop easy listening',\n",
    "            'disgust': 'industrial metal experimental rock'\n",
    "        }\n",
    "        self.df = self._load_data(data_path)\n",
    "        if not self.df.empty:\n",
    "            self.tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "            self.tfidf_matrix = self.tfidf_vectorizer.fit_transform(self.df['tags'])\n",
    "            print(\" Music Recommender initialized.\")\n",
    "\n",
    "    def _load_data(self, data_path):\n",
    "        if not os.path.exists(data_path):\n",
    "            print(f\" ERROR: Music data not found at '{data_path}'. Please check your project structure.\")\n",
    "            return pd.DataFrame()\n",
    "        return pd.read_csv(data_path)\n",
    "\n",
    "    def recommend_songs(self, emotion, num_recommendations=10):\n",
    "        if self.df.empty: return pd.DataFrame()\n",
    "        query_tags = self.emotion_to_music_map.get(emotion.lower())\n",
    "        if not query_tags: return pd.DataFrame()\n",
    "        query_vector = self.tfidf_vectorizer.transform([query_tags])\n",
    "        cosine_similarities = cosine_similarity(query_vector, self.tfidf_matrix).flatten()\n",
    "        top_song_indices = cosine_similarities.argsort()[:-num_recommendations-1:-1]\n",
    "        return self.df.iloc[top_song_indices][['artist_name', 'title']]\n",
    "\n",
    "# --- Step 3: Configuration and Model Loading ---\n",
    "\n",
    "MODEL_PATH = 'models/cnn_emotion_model.h5' # Or: 'models/vgg16_emotion_model_50_epochs.h5'\n",
    "MUSIC_DATA_PATH = 'data/music_processed/processed_music_tags.csv'\n",
    "EMOTION_MAP = {0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happy', 4: 'sad', 5: 'surprise', 6: 'neutral'}\n",
    "\n",
    "try:\n",
    "    emotion_model = tf.keras.models.load_model(MODEL_PATH)\n",
    "    print(f\" Emotion model loaded successfully from '{MODEL_PATH}'.\")\n",
    "except Exception as e:\n",
    "    print(f\" FATAL ERROR: Could not load the emotion model from '{MODEL_PATH}'.\")\n",
    "    print(\"Please ensure your notebook is in the main project folder and the path is correct.\")\n",
    "    emotion_model = None\n",
    "    \n",
    "music_recommender = MusicRecommender(MUSIC_DATA_PATH)\n",
    "\n",
    "# --- Step 4: Define the Prediction Function ---\n",
    "def predict_emotion_from_image_bytes(image_bytes, model):\n",
    "    if model is None:\n",
    "        print(\" ERROR: Emotion model is not loaded. Cannot predict.\")\n",
    "        return None\n",
    "    try:\n",
    "        if isinstance(image_bytes, str): image_bytes = image_bytes.encode('utf-8')\n",
    "        nparr = np.frombuffer(image_bytes, np.uint8)\n",
    "        img = cv2.imdecode(nparr, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(\" ERROR: OpenCV could not decode the image.\")\n",
    "            return None\n",
    "        if model.input_shape[-1] == 3: img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "        img_resized = cv2.resize(img, (48, 48))\n",
    "        img_normalized = img_resized / 255.0\n",
    "        img_expanded = np.expand_dims(img_normalized, axis=0)\n",
    "        if len(img_expanded.shape) < 4 and model.input_shape[-1] == 1: img_expanded = np.expand_dims(img_expanded, axis=-1)\n",
    "        prediction = model.predict(img_expanded, verbose=0)\n",
    "        return EMOTION_MAP[np.argmax(prediction)]\n",
    "    except Exception as e:\n",
    "        print(f\" An unexpected error occurred during prediction: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# --- Step 5: Create and Display the Interactive UI ---\n",
    "uploader = widgets.FileUpload(accept='image/*', description='Upload Image', button_style='primary')\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def on_file_upload(change):\n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        uploaded_file = change['new']\n",
    "        if not uploaded_file: return\n",
    "        file_info = uploaded_file[0]\n",
    "        image_bytes = file_info['content']\n",
    "        \n",
    "        print(\"--- Analyzing New Image ---\")\n",
    "        display(Image.open(io.BytesIO(image_bytes)))\n",
    "        \n",
    "        detected_emotion = predict_emotion_from_image_bytes(image_bytes, emotion_model)\n",
    "        \n",
    "        if detected_emotion:\n",
    "            print(f\"\\n Detected Emotion: {detected_emotion.upper()}\")\n",
    "            playlist = music_recommender.recommend_songs(detected_emotion)\n",
    "            if not playlist.empty:\n",
    "                print(\"\\n--- ðŸŽ¶ Here is your personalized playlist ---\")\n",
    "                display(playlist)\n",
    "\n",
    "                # --- NEW ANALYSIS SECTION ---\n",
    "                print(\"\\n--- How This Playlist Was Chosen ---\")\n",
    "                emotion_keywords = music_recommender.emotion_to_music_map.get(detected_emotion, \"\")\n",
    "                print(f\"1. Emotion Detected: The AI model analyzed the image and identified the emotion as '{detected_emotion}'.\")\n",
    "                print(f\"2. Keyword Mapping: This emotion was then translated into a set of musical keywords: '{emotion_keywords}'.\")\n",
    "                print(\"3. Song Matching: Finally, the system searched a library of songs to find the ones whose tags most closely matched these keywords.\")\n",
    "\n",
    "        else:\n",
    "            print(\"\\n Could not detect an emotion. Please check the error messages above.\")\n",
    "\n",
    "uploader.observe(on_file_upload, names='value')\n",
    "\n",
    "print(\"\\n--- MoodMate Interactive UI ---\")\n",
    "print(\"Upload an image of a face to get started.\")\n",
    "display(uploader, output_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6edc42a-cc76-411c-8993-c3996eb9c434",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
